---
title: "Stawberries: exploratory data analysis"
author: Yueqi(Charlene) Jin
date: 2023 Oct 15
format: pdf
engine: knitr
---

*Data research final Goal:*

*1.Use Frequency of Top 15 Chemicals in various State*

*2.Visualize all chemicals and differentiate them by color based on their safety and toxicity*

*3.Toxic & Safe Chemical Frequency by State*

*4.Toxic Chemical Use Frequency in Various States from 2016 to 2021*

*5.Safe Chemical Use Frequency in Various States from 2016 to 2021*

*6. Average Value of Strawberries using toxic chemicals & safe chemicals*

## Data acquisition and assessment

```{r setup, include=FALSE}
#| label: Load libraries
#| warning: false
#| message: false
#| echo: false
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("bayesplot", "knitr", "kableExtra", "tidyverse", "reshape2", "stringr", "ggplot2", "rstanarm", "dplyr","magrittr","hrbrthemes","ggiraphExtra","ggTricks","igraph","ggraph","ggpol","huxtable","viridis","sf","maps","ggmap")

```

<!-- Read the file -->

```{r warning=FALSE, message=FALSE}
#| label: read data - glimpse 
#| warning: false
#| message: false
#| echo: false
strawberry <- read_csv("strawberry.csv", col_names = TRUE)
glimpse(strawberry)

```

*We see that the top 10 states with the highest total value of strawberries each year.*

```{r}

# Convert the Value column from non-numeric format to numeric
strawberry$Value <- as.numeric(gsub("[^0-9.]", "", strawberry$Value))

# Group data by Year and State, then compute the total value for each state per year
annual_state_value <- strawberry %>%
  group_by(Year, State) %>%
  summarise(Total_Value = sum(Value, na.rm = TRUE), .groups = "drop") %>%
  ungroup()

# Sort data by Year and total value, then retrieve and format the top 10 states 
# by value for each year

top_states_each_year <- annual_state_value %>%
  group_by(Year) %>%
  arrange(desc(Total_Value)) %>%
  slice_head(n = 10) %>%
  summarise(Top_10_States = paste(State, collapse=", "), .groups = "drop") %>%
  ungroup()

# Display the results
print(top_states_each_year)

```

```{r}
# Filter to keep only the top 10 states for each year
top_states_each_year_data <- annual_state_value %>%
  group_by(Year) %>%
  top_n(10, Total_Value) %>%
  ungroup()

# Plot the heatmap to visualize top 10 States with the Highest Total Value 
# of Strawberries Each Year
ggplot(top_states_each_year_data, aes(x = as.factor(Year), y = State, fill = Total_Value)) +
  geom_tile() +
  scale_fill_viridis(name = "Total Value") +
  labs(title = "Top 10 States with the Highest Total Value of Strawberries Each Year",
       x = "Year",
       y = "State") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Data cleaning and organization

<!-- Remove columns with a single value in all columns -->

```{r}
#| label: drop one-item columns
#| echo: false

## define function
drop_one_value_col <- function(df){
col_name <- NULL
col_val <- NULL
suppressWarnings({
for(i in 1:dim(df)[2]){
if((df |> distinct(df[,i]) |> count()) == 1){
  col_name = c(col_name, colnames(df[i]))
  col_val = c(col_val, df[1,i])  
} }
})

if(is.null(col_name)){return("No Columns to drop")}else{
   col_val = unlist(col_val)
   attributes(col_val) = NULL
   drp = data.frame(col_name, col_val)
   return(drp)
   }
}

str <- drop_one_value_col(strawberry)
# str |> kable(caption = "Dropped Single-Value Columns: names and values")
str <- str$col_name
strawberry <- strawberry |> select(!all_of(str))

## applying the function a second time 
## tests the function when there aren't any 
## one-value columns
#####  drop_one_value_col(strawberry)

```

<!-- Glimpse of strawberry data after dropping single-value columns. -->

```{r}
#| label: glimpse of strawberry data
#| echo: false

glimpse(strawberry)

```

<!-- Examine California data -->

```{r}
#| label: examine California data
#| echo: false

## filter rows of California data from the CENSUS data
calif_census <- strawberry |> filter((State=="CALIFORNIA") & (Program=="CENSUS"))

## ## filter rows of California data from the SURVEY data
calif_survey <- strawberry |> filter((State=="CALIFORNIA") & (Program=="SURVEY"))
census_col <- colnames(calif_census)
survey_col <- colnames(calif_survey)

```

<!-- Separate CENSUS and SURVEY into two Data Frames -->

```{r}
#| label: split srawberry into census and survey pieces
#| echo: false

strwb_census <- strawberry |> filter(Program == "CENSUS")
strwb_survey <- strawberry |> filter(Program == "SURVEY")
rm(calif_census, calif_survey, state_all)
strwb_census <- strwb_census |>
separate_wider_delim(  cols = `Data Item`,
                         delim = ",",
                         names = c("Fruit",
                                 "temp1",
                                 "temp2",
                                 "temp3"),
                         too_many = "error",
                         too_few = "align_start"
                       )

## split temp1 into crop_type, Prop_acct
strwb_census <- strwb_census |>
  separate_wider_delim(  cols = temp1,
                         delim = " - ",
                         names = c("crop_type",
                                 "prop_acct"),
                         too_many = "error",
                         too_few = "align_start"
                       )

#glimpse(strwb_census)
strwb_census$crop_type <- str_trim(strwb_census$crop_type, side = "both")
strwb_census$temp2 <- str_trim(strwb_census$temp2, side = "both")
strwb_census$temp3 <- str_trim(strwb_census$temp3, side = "both")

strwb_census <- strwb_census |> mutate(`Fresh Market` = temp2, .after = temp2)

## Remove cells in `Fresh Market` column 
##   that begin "MEASURED"
strwb_census$`Fresh Market` <- strwb_census$`Fresh Market` |> str_replace( "^MEA.*", "")

## Remove cells in `Fresh Market` column 
##   that begin "PROCESSING" 
strwb_census$`Fresh Market` <- strwb_census$`Fresh Market` |> str_replace( "^P.*", "")

## substitute a space for NA in `Fresh Market` column
strwb_census$`Fresh Market`[is.na(strwb_census$`Fresh Market`)] <- ""  

## in temp2 column, remove cells that begin "FRESH"
 strwb_census$temp2 <- strwb_census$temp2 |> str_replace("^F.*", "")

## Now fix the entries in the `Fresh Market` column
##   Remove "FRESH MARKET - " from the cells
strwb_census$`Fresh Market` <- strwb_census$`Fresh Market` |> str_replace("^FRESH MARKET - ", "")


## Make a copy of temp2 named `Process Market`
strwb_census <- strwb_census |> mutate(`Process Market` = temp2, .after = temp2)

## remove `Process Market` cells beginning "MEASURED"
strwb_census$`Process Market` <-  strwb_census$`Process Market` |> str_replace("^MEA.*", "")

## substitute space for NA in `Process Market` column
strwb_census$`Process Market`[is.na(strwb_census$`Process Market`)] <- ""

## In temp2, remove cells that begin "PROCESSING"
strwb_census$temp2 <- strwb_census$temp2 |> str_replace("^P.*", "")

## In `Processing Market`, remove "PROCESSING - " from cells
strwb_census$`Process Market` <-  strwb_census$`Process Market` |> str_replace("PROCESSING - ", "") 


## substitute a space for NA in prop_acct column
strwb_census$prop_acct[is.na(strwb_census$prop_acct)] <- "" 

## substitute a space for NA in temp2 column
strwb_census$temp2[is.na(strwb_census$temp2)] <- "" 

## substitute a space for NA in temp2 column
strwb_census$temp3[is.na(strwb_census$temp3)] <- "" 


strwb_census <- strwb_census |> unite(temp2, temp3, col="Metric", sep="")

## Now fix the entries in the Metric column
##   Remove "MEASURED IN " from the cells
strwb_census$Metric <- strwb_census$Metric |> str_replace("MEASURED IN ", "")

## move Metric to the end
strwb_census <- strwb_census |> relocate(Metric, .before = Domain)

#strwb_census <- strwb_census |> relocate(`Process Market`, .before = Metric)

strwb_census <- strwb_census |> rename(Totals = prop_acct)

#drop_one_value_col(strwb_census)
```

<!-- ## The Value column transformation -->

```{r}
#| label: define functions dcomma and footnote finder
#| echo: false
#| warning: false
#| message: false
#| eval: true

vals <- strwb_census$Value

g1 <- sub(",", "", vals)
# vals[1:20]
# g1[1:20]

g2 <- gsub(",", "", vals)
# vals[1:20]
# g2[1:20]

## stringr - str_replace(), str_replace_all()

## LOOK -- see ref for stingr pkg
a <- vals |> str_detect(",")

# vals[1:20]
# a[1:20]

## Still strings!!
b <- vals |> str_replace(",", "")
# vals[1:20]
# b[1:20]

c <- vals |> str_replace_all(",", "")
# vals[1:20]
# c[1:20]

## Now notice what happens when the
## the strings of digits are cast to numerics.

## for example
c <- as.numeric(c)
# c[1:20]

### remove commas from Value entries
dcomma <- function(c){
  x_new <- as.numeric(gsub(",", "", c))
  return(x_new)
}

```

######################################### footnotes

```{r}
## finds single uppor case Character in parens in s2
## e.g. "(D)"
## To fine the location and value of the footnotes

v <- strwb_census$Value

## find the footnote locations
## fn_i: locations 
fn_i <- v |> str_detect("^\\([:upper:]\\)$") ## returns

## dcomma returns numbers and NA's
v1 <- dcomma(v)

## locations of NA's
na_i <- is.na(v1)

dcomma <- function(c){
  suppressWarnings({
  xnew = as.numeric(gsub(",", "", c))
  fns = unique(c[is.na(xnew)])
  vtran = list("new_vec" = xnew, "footnotes" = fns)
  return(vtran)
  })
}

v_trns <- dcomma(v)

a <- v_trns$new_vec
 # a[1:20]
 # v_trns$footnotes

```

## EDA

*Chemicals: Firstly we divide the chemical composition into two columns and eliminating irrelevant variables.*

```{r}
stb_survey <- strwb_survey %>%
  filter(str_detect(`Data Item`, "MEASURED IN")) %>%
  mutate(`Data Item` = str_extract(`Data Item`, "(?<=MEASURED IN ).*"))
stb_survey <- stb_survey %>%
  mutate(
    Chemical = if_else(str_detect(`Domain Category`, "\\(.*=.*\\)"),
                       str_extract(`Domain Category`, "(?<=\\().*?(?=\\=)"),
                       NA_character_),
    Chemical_Code = if_else(str_detect(`Domain Category`, "\\(.*=.*\\)"),
                            str_extract(`Domain Category`, "(?<=\\=).*?(?=\\))"),
                            NA_character_)
  )


stb_survey <- subset(stb_survey, select = -Program)
stb_survey <- subset(stb_survey, select = -`Domain Category`)

stb_survey$Chemical_Code_num <- as.numeric(stb_survey$Chemical_Code)
stb_survey$Chemical_Code_str <- ifelse(is.na(stb_survey$Chemical_Code_num),NA,
                                       sprintf("%06d", 
                                               stb_survey$Chemical_Code_num))
```

*Handing Missing Values, Outliers, and Duplicates*

```{r}
stb_survey <- stb_survey[, !sapply(stb_survey, function(col) all(is.na(col)))]
stb_survey <- stb_survey[!is.na(stb_survey$Value), ]
stb_survey <- stb_survey[stb_survey$State != "OTHER STATES", ]

```

```{r}
strwb_census$`CV (%)`<- as.numeric(strwb_census$`CV (%)`)
strwb_census <- strwb_census %>%
  select(-Program,-`Period`,-Fruit,-crop_type,-Domain,-`Domain Category`)

```

*Create a detailed visualization that illustrates the varying frequencies at which each individual chemical substance is utilized across the various states.*

```{r}
stb_survey$Domain <- gsub("CHEMICAL,", "", stb_survey$Domain)
stb_survey$Domain <- trimws(stb_survey$Domain)
write.csv(stb_survey, file = "stb_survey.csv", row.names = FALSE)

top_chemicals_data <- stb_survey %>%
  count(Chemical) %>%
  arrange(-n) %>%
  head(15)

# Extract data for these top 15 chemicals from the original dataset.
subset_stb_survey <- stb_survey %>%
  filter(Chemical %in% top_chemicals_data$Chemical)

p <- ggplot(subset_stb_survey, aes(x = Chemical, fill = State)) +
  geom_bar(position = "stack", stat = "count") +  
  scale_fill_brewer(palette = "Set1") +  
  labs(title = "Use Frequency of Top 15 Chemicals in various State", 
       x = NULL, y = "Use Frequency") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  
    axis.ticks = element_blank(),
    legend.title = element_blank(),
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
  ) +
  coord_polar(theta = "y") 
print(p)

```

*The chart visualizes the use frequency of the top 15 chemicals across various states.California has the highest use frequency for many of the chemicals, with its usage often reaching the 500-mark.Florida and Michigan also show notable use frequencies, but they generally fall below the level of California. Some chemicals, such as those corresponding to the purple and orange segments (possibly Ohio and Oregon), have a more consistent usage frequency across the spectrum of chemicals.The chemicals listed on the left side of the chart (like abamectin, acetamiprid, azoxystrobin) have a more consistent usage frequency across different states.There is a chemical labeled as NA, suggesting that there might be some missing or unclassified data in this dataset.Several states like New York, North Carolina, and Wisconsin have relatively lower frequencies in the use of these top chemicals when compared to states like California.*

*Then Create two subsets, poisons_chem and safe_chem, by filtering based on the values in the 'Chemical' column from the stb_survey data table.Visualize all chemicals and differentiate them by color based on their safety.*

```{r}
#Data Cleaning: Remove blanks and standardize to lowercase, extract unique
#chemical names and create a new dataframe to store these distinct chemical names

stb_survey$Chemical <- tolower(trimws(stb_survey$Chemical))
unique_chemicals <- unique(stb_survey$Chemical)
unique_chemicals_df <- data.frame(Chemical = unique_chemicals)
write.csv(unique_chemicals_df, file = "unique_chemicals.csv", row.names = FALSE)

poisonous_chemicals <- c("azoxystrobin", "blad", "boscalid", 
                         "bt subsp kurstaki evb-113-19", "captan", 
                         "copper octanoate", "cyflufenamid", "cyprodinil", 
                         "difenoconazole", "fenhexamid", "fludioxonil", 
                         "fluopyram", "fluxapyroxad", "fosetyl-al", "isofetamid", 
                         "mefenoxam", "mono-potassium salt", "myclobutanil", 
                         "penthiopyrad", "polyoxin d zinc salt", "propiconazole",
                         "pyraclostrobin", "pyrimethanil", "quinoline", "sulfur", 
                         "tetraconazole", "thiophanate-methyl", "thiram", 
                         "trifloxystrobin", 
                         "triflumizole", "carfentrazone-ethyl", "flumioxazin", 
                         "glyphosate iso. salt", "glyphosate pot. salt", 
                         "napropamide", "oxyfluorfen", "paraquat", "pendimethalin", 
                         "abamectin", "acequinocyl", "acetamiprid", "azadirachtin", 
                         "bifenazate", "bifenthrin", "bt kurstak abts-1857",
                         "bt kurstaki abts-351", "bt kurstaki eg7841", 
                         "bt kurstaki sa-11", "bt sub aizawai gc-91",
                         "buprofezin", "burkholderia a396 cells & media",
                         "chlorantraniliprole", 
                         "chromobac subtsugae praa4-1 cells and spent media", 
                         "cyantraniliprole", "cyflumetofen", "diazinon", "etoxazole", 
                         "fenbutatin-oxide", "fenpropathrin", "fenpyroximate", 
                         "flonicamid", "flupyradifurone", "helicoverpa zea npv",
                         "hexythiazox", "imidacloprid", "malathion", 
                         "methoxyfenozide", "naled", "novaluron", 
                         "petroleum distillate", "piperonyl butoxide",
                         "pyrethrins", "pyridaben", "pyriproxyfen",
                         "spinetoram", "spinosad", "spiromesifen", 
                         "thiamethoxam", "acibenzolar-s-methyl", 
                         "chloropicrin", "dichloropropene", "flutriafol", 
                         "metam-potassium", "peroxyacetic acid", "potassium silicate",
                         "pydiflumetofen", "clethodim", "copper ethanolamine", 
                         "dimethenamid", "fluroxypyr 1-mhe", "halosulfuron-methyl",
                         "kantor", "carbaryl", "fenazaquin", "sulfoxaflor", 
                         "cytokinins", "ethephon", "indolebutyric acid", 
                         "copper hydroxide", "glufosinate-ammonium", 
                         "sulfentrazone", "chlorpyrifos", "zeta-cypermethrin", 
                         "metaldehyde", "metam-sodium", "copper chloride hyd.",
                         "dodine", "flutolanil", "2,4-d, dimeth. salt", "2,4-d, 
                         triiso. salt", 
                         "cypermethrin", "alkyl. dim. benz. am", "decyldimethyloctyl",
                         "didecyl dim. ammon.", "dimethyldioctyl", "iprodione", 
                         "cyflumetofen", "emamectin benzoate", "lambda-cyhalothrin",
                         "spirotetramat", "dimethyl disulfide (dmds)", 
                         "copper oxide", "ammonium pelargonate", "flubendiamide",
                         "methyl bromide", "chlorothalonil", "cyazofamid",
                         "mancozeb", "endosulfan", "clopyralid mono salt", 
                         "simazine", "terbacil", "ferric sodium edta", "clomazone")

safe_chemicals <- c("bacillus amyloliquefaciens mbi 600", "bacillus amyloliquefac f727", 
                    "bacillus amyloliquefaciens strain d747", "bacillus pumilus", 
                    "bacillus subtilis", "beauveria bassiana", "borax decahydrate",
                    "canola oil", "streptomyces lydicus", "neem oil", 
                    "neem oil, clar. hyd.", "hydrogen peroxide", "iron phosphate", 
                    "mineral oil", "potassium bicarbon.", "potassium salts",
                    "soybean oil", "aureobasidium pullulans dsm 14940", 
                    "aureobasidium pullulans dsm 14941", "trichoderma harz.",
                    "trichoderma virens strain g-41", "gliocladium virens", 
                    "bacillus subt. gb03", "paecilomyces fumosor", 
                    "reynoutria sachaline", "pseudomonas chlororaphis strain afs009",
                    "capsicum oleoresin extract", "garlic oil", "capric acid",
                    "caprylic acid", "mustard oil", "capsaicin", "harpin a b protein")

all_chemicals <- c(safe_chemicals, poisonous_chemicals)
unique_chemicals <- unique(all_chemicals)

df <- data.frame(
  name = unique_chemicals, 
  type = ifelse(unique_chemicals %in% safe_chemicals, "safe", "toxic")
)
graph <- graph.empty(n = 0, directed = FALSE)
graph <- add_vertices(graph, nrow(df), name = df$name, type = df$type)

ggraph(graph, layout = 'circle') + 
  geom_node_point(aes(color = type), size = 3) + 
  geom_node_text(aes(label = name), nudge_y = 0.1, check_overlap = TRUE, angle = TRUE) +
  scale_color_manual(values = c("safe" = "darkmagenta", "toxic" = "#D93600")) +
  theme_void() +
  theme(legend.position = "right")

stb_survey$Chemical <- trimws(stb_survey$Chemical)

poisons_chem <- subset(stb_survey, Chemical %in% poisonous_chemicals)
safe_chem <- subset(stb_survey, Chemical %in% safe_chemicals)

```

*Deal with preprocessing data, calculate the count of toxic and non-toxic chemicals for each state.And Exclude states where both toxic and non-toxic chemical counts are zero.*

```{r}
stb_grouped <- stb_survey %>%
  group_by(State) %>%
  summarise(
    toxic_count = sum(Chemical %in% poisonous_chemicals),
    safe_count = sum(Chemical %in% safe_chemicals)
  ) %>%
  filter(toxic_count > 0 | safe_count > 0) 
options(repr.plot.width=10, repr.plot.height=8)

ggplot(stb_grouped, aes(y = State)) + 
  geom_segment(aes(x = safe_count, xend = toxic_count, yend = State), color = 'grey') +
  geom_point(aes(x = safe_count, color = "Safe"), size = 4) +
  geom_point(aes(x = toxic_count, color = "Toxic"), size = 4) +
  scale_color_manual(values = c("Toxic" = "darkblue", "Safe" = "darkmagenta")) +  
  labs(x="Count", y="State", title="Toxic & Safe Chemical Frequency by State",
       subtitle = "States with zero count for both are excluded",
       color="Chemical Type") +
  theme_minimal() +
  theme(legend.position = "top")

```

*Among the four listed states, California has the highest frequency of both safe and toxic chemical usage.For safe chemicals, there is no safe chemical in Oregon and Washington.When considering toxic chemicals, Washington's frequency is noticeably higher than that of Oregon.*

*Toxic Chemical Frequency in Various States from 2016 to 2021*

```{r}
# Filter the data to include only the specified domains
selected_domains <- c("INSECTICIDE", "FUNGICIDE", "HERBICIDE", "OTHER")
poisons_chem_selected <- poisons_chem %>%
  filter(Domain %in% selected_domains)

# Create the plot with a custom color scale
toxic_plot1 <- ggplot(data = poisons_chem_selected, 
           aes(x = Year, y = Domain, col = State)) +  
  geom_jitter() +
  xlab('Year: 2016 - 2021') + 
  ylab('Chemical Type') + 
  labs(title = 'Toxic Chemical Frequency in Various States from 2016 to 2021', 
       subtitle = 'Chemical type by year') +
  scale_color_manual(values = c("darkmagenta", "darkblue", "darkgreen", "darkorange"))
toxic_plot1
```
*From the plot regarding toxic chemicals, we can find that insecticide and fungicide widely used in strawberry farming in California and Florida. Strawberry farming in Washington and Oregon only used insecticides, herbicides, and fungicides in 2016, but did not use them in subsequent years.*

*Safe Chemical Frequency in Various States from 2016 to 2021*
```{r}
# Filter the data to include only the specified domains
selected_domains <- c("INSECTICIDE", "FUNGICIDE", "HERBICIDE", "OTHER")
safe_chem_selected <- safe_chem %>%
  filter(Domain %in% selected_domains)

# Create the plot with a custom color scale
toxic_plot1 <- ggplot(data = safe_chem_selected, 
           aes(x = Year, y = Domain, col = State)) +  
  geom_jitter() +
  xlab('Year: 2016 - 2021') + 
  ylab('Chemical Type') + 
  labs(title = 'Safe Chemical Frequency in Various States from 2016 to 2021', 
       subtitle = 'Chemical type by year') +
  scale_color_manual(values = c("darkmagenta", "darkblue", "darkgreen", "darkorange"))
toxic_plot1
```
*From the plot regarding safe chemicals, we can find that insecticide and fungicide widely used in strawberry farming in California and Florida in all years. In 2016, strawberry farming in Washington only used fungicides and strawberry farming in Oregon only used others, but did not use them in subsequent years.*

*We observe the distribution of the average value of strawberries in each state when using toxic chemicals.*
```{r}
poisons_chem$Value <- as.numeric(gsub("[^0-9.]", "", poisons_chem$Value))
us_states <- map_data("state")

# Ensure state names match. Convert both to lowercase to avoid discrepancies due to case.
poisons_chem$State <- tolower(poisons_chem$State)
us_states$region <- tolower(us_states$region)

# Calculate the average value for each state
state_avg_values <- poisons_chem %>%
  group_by(State) %>%
  summarise(Avg_Value = mean(Value, na.rm = TRUE), .groups='drop')

# Merge the map data and the average values
map_data <- left_join(us_states, state_avg_values, by = c("region" = "State"))

# If there are NA values in the merged data, you can replace them with zeros.
map_data$Avg_Value[is.na(map_data$Avg_Value)] <- 0

#Find the centroid of each state for placing the state label
state_centroids <- map_data %>%
  group_by(region) %>%
  summarise(cent_x = mean(long, na.rm = TRUE), cent_y = mean(lat, na.rm = TRUE), 
            Avg_Value = first(Avg_Value))

#Filter centroids to keep only those states that have a non-zero Avg_Value
state_centroids <- filter(state_centroids, Avg_Value > 0)

#Create a choropleth map with shades of blue and label states with non-zero average values
ggplot(data = map_data, aes(x = long, y = lat, fill = Avg_Value)) +
  geom_polygon(aes(group = group), color = "white") +
  geom_text(data = state_centroids, aes(x = cent_x, y = cent_y, label = region),
            size = 2.5, check_overlap = TRUE) +
  scale_fill_gradient(name = "Average Value of Strawberries", low = "lightblue", 
                      high = "darkblue") +
  labs(title = "Average Value of Strawberries by State under the Use of Toxic Chemicals") +
  coord_fixed(1.3) +
  theme_void()
```

*We observe the distribution of the average value of strawberries in each state when using safe chemicals.*
```{r}
safe_chem$Value <- as.numeric(gsub("[^0-9.]", "", safe_chem$Value))
us_states <- map_data("state")

# Ensure state names match. Convert both to lowercase to avoid discrepancies due to case.
safe_chem$State <- tolower(safe_chem$State)
us_states$region <- tolower(us_states$region)

# Calculate the average value for each state
state_avg_values <- safe_chem %>%
  group_by(State) %>%
  summarise(Avg_Value = mean(Value, na.rm = TRUE), .groups='drop')

# Merge the map data and the average values
map_data <- left_join(us_states, state_avg_values, by = c("region" = "State"))

# If there are NA values in the merged data, you can replace them with zeros.
map_data$Avg_Value[is.na(map_data$Avg_Value)] <- 0

# Find the centroid of each state for placing the state label
state_centroids <- map_data %>%
  group_by(region) %>%
  summarise(cent_x = mean(long, na.rm = TRUE), cent_y = mean(lat, na.rm = TRUE), 
            Avg_Value = first(Avg_Value))

# Filter centroids to keep only those states that have a non-zero Avg_Value
state_centroids <- filter(state_centroids, Avg_Value > 0)

# Create a choropleth map with shades of blue and label states 
# with non-zero average values
ggplot(data = map_data, aes(x = long, y = lat, fill = Avg_Value)) +
  geom_polygon(aes(group = group), color = "white") +
  geom_text(data = state_centroids, aes(x = cent_x, y = cent_y, label = region), 
            size = 2.5, check_overlap = TRUE) +
  scale_fill_gradient(name = "Average Value of Strawberries", low = "lightblue", 
                      high = "darkblue") +
  labs(title="Average Value of Strawberries by State under the Use of Safe Chemicals") +
  coord_fixed(1.3) +
  theme_void()

```
*Based on the distribution from the two maps, we conclude that under both the use of toxic and non-toxic chemicals, the average value of strawberries in California is the highest. Furthermore, when using toxic chemicals, the average value of strawberries in Washington is the lowest.*

<p style="page-break-before: always">

</p>

## References

*https://quickstats.nass.usda.gov/src/glossary.pdf*

*https://quickstats.nass.usda.gov/param_define*
